{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e986fde9-6709-4d3d-bdca-d3c323f37e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U gensim -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f613143-321f-4c0b-b11a-2fc8ef887f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import random\n",
    "import unicodedata\n",
    "\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dcabc9-d850-4cee-97bf-5df83f8dae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfd7f2f-7593-44b2-a73b-c4f99beb88ae",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d4694-8f7a-43dd-afd5-ad3f5d9eaed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path.home() / \".models\"\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "MODELS_DIR = BASE_DIR / \"models\"\n",
    "\n",
    "corpus_path = DATA_DIR / \"classical_bo\"\n",
    "model_path = str((MODELS_DIR / \"doc2vec_classical_bo\").resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6550d02-b627-46d7-a1b8-fdf0acd70963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    for pecha_path in path.iterdir():\n",
    "        if not pecha_path.is_dir(): continue\n",
    "        for fn in pecha_path.iterdir():\n",
    "            if not 'tokenize' in fn.name: continue\n",
    "            yield fn\n",
    "            \n",
    "def is_punt(word):\n",
    "    for punt in [\"།\", \"།།\", \"༄༅\"]:\n",
    "        if punt in word:\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "def tokenize(text):\n",
    "    return [token for token in text.split() if token and not is_punt(token)]\n",
    "    \n",
    "def get_sentences(fns):\n",
    "    for fn in fns:\n",
    "        for sentence in fn.open('r'):\n",
    "            if len(sentence.split()) < 3: continue\n",
    "            yield tokenize(unicodedata.normalize(\"NFKC\", sentence.strip()))\n",
    "\n",
    "def create_dataset(sentences, tokens_only=False):\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        tokens = sentence # already tokenize\n",
    "        print(tokens)\n",
    "        if tokens_only:\n",
    "            yield tokens\n",
    "        else:\n",
    "            # For training data, add tags\n",
    "            yield gensim.models.doc2vec.TaggedDocument(tokens, [i])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b43e4-601c-4dd0-9571-d44f6387b645",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_files(corpus_path)\n",
    "train_files, test_files = train_test_split(list(files), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b5a712-9dae-4fa4-afa8-0772d4f552a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = get_sentences(train_files)\n",
    "test_sents = get_sentences(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7df41c-a857-4482-a66e-ea94af23c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = list(create_dataset(train_sents))\n",
    "test_corpus = list(create_dataset(test_sents, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297210b3-c61c-4501-bdb1-9be8f480a3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id = random.randint(0, len(train_corpus) - 1)\n",
    "doc_id, train_corpus[doc_id: doc_id+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe981c4-f47d-4b5d-bab7-3149f85cc428",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_corpus) == train_corpus[-1].tags[0] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d0e25-340f-43db-8192-c9b69d5b9f56",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f908ffe1-de04-4950-8134-69d225a0e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d26fed9-599a-4b1a-be24-1f3606461a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bf83bb-671b-4e1a-9aa0-013f381b0b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4704393-32a7-4e3c-9467-868fba2483e0",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa87cf-abe1-4f47-bf3d-da1be66c5816",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.infer_vector([\"རིམ་པ་\", \"བཞིན་\", \"དུ་\", \"སྦྱིན་པ་\", \"ལ་\", \"བྱ་\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb5ccc4-595a-49ce-a5b1-251e06edd436",
   "metadata": {},
   "source": [
    "## Save and Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be520858-4a44-4ed1-9a86-fe2fc5b2e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67113b73-da5d-4852-bc36-10a766da789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0558eb-fb77-4a0c-a192-9af184c0f056",
   "metadata": {},
   "source": [
    "## Assessing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200cf695-621f-4654-b3c0-52c1e62a4e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e2293-580c-4f48-bb0a-4cf8189aa799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f324752c-417b-4e7e-9a88-7b057de0575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id = 1\n",
    "print('Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213e7845-3f9c-43dd-8bdc-adeb7d9916f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random document from the corpus and infer a vector from the model\n",
    "import random\n",
    "doc_id = random.randint(0, len(train_corpus) - 1)\n",
    "\n",
    "# Compare and print the second-most-similar document\n",
    "print('Train Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "sim_id = second_ranks[doc_id]\n",
    "print('Similar Document {}: «{}»\\n'.format(sim_id, ' '.join(train_corpus[sim_id[0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d573a0-e64d-4c51-8f7f-1d65f0ce14ac",
   "metadata": {},
   "source": [
    "## Testing the Model\n",
    "Using the same approach above, we’ll infer the vector for a randomly chosen test document, and compare the document to our model by eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9407aa97-8927-45ef-b09f-ec9f23eab144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2afe58-2c97-4fbf-a915-98a2ae757f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
